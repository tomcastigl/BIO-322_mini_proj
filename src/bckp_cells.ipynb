{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data we are interested in is VALENCE.PLEASANTNESS, wich take values between 0 and 100. The objective is to create a model estimating the VALENCE.PLEASANTNESS given the inputs \"Intensity, \"SWEETORSOUR\"(sure?), and V2 to V11787, which represent the presence or not of a corresponding physiochemical feature in the smelled molecule. At first sight of the data plotted above, we can see that the SWEETORSOUR variable seems have a relatively big impact on VALENCE.PLEASANTNESS (actually it does not proves anything, it is just an early observation). Now we look at some randomly chosen physiochemical features comparing the means of VALENCE.PLEASANTNESS when they are present or not.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the means with or without some randomly chosen physiochemical features\n",
    "for(col in sample(2:nrow(data),7)){\n",
    "    idx.presence<-c()\n",
    "    idx.nonpresence<-c()\n",
    "    for(i in 1:nrow(data)){\n",
    "        if(data[col,i]==1){\n",
    "            idx.presence<-append(idx.presence,i)\n",
    "        }else{\n",
    "            idx.nonpresence<-append(idx.nonpresence,i)\n",
    "        }\n",
    "    }\n",
    "    #message(\"presence mean of \", colnames(data)[col],\" \",mean(data$VALENCE.PLEASANTNESS[idx.presence]))\n",
    "    #message(\"nonpresence mean \",colnames(data)[col],\" \",mean(data$VALENCE.PLEASANTNESS[idx.nonpresence]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Let's start to create a basic linear regression model on all the data. This model will be the base to be improved to try and get the best linear model. We separate all the data in a training set (2/3 of the whole data is taken as training set because we will separate it in a validation and actual training set later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a training (for now, it will be split later) and test set.\n",
    "idx.train<-sample(nrow(data),nrow(data)*(2/3))\n",
    "data.test<-data[-idx.train,]\n",
    "data<-data[idx.train,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next cell is really slow, because of all the predictors (11789 !!!), and since p>>n we will largely overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic.lm.fit<-lm(VALENCE.PLEASANTNESS~.,data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in predict(basic.lm.fit, data = data): objet 'basic.lm.fit' introuvable\n",
     "output_type": "error",
     "traceback": [
      "Error in predict(basic.lm.fit, data = data): objet 'basic.lm.fit' introuvable\nTraceback:\n",
      "1. predict(basic.lm.fit, data = data)"
     ]
    }
   ],
   "source": [
    "train.pred<-predict(basic.lm.fit,data=data)\n",
    "test.pred<-predict(basic.lm.fit,data=data.test)\n",
    "trainMSE<-mean((data$VALENCE.PLEASANTNESS-train.pred)^2)\n",
    "testMSE<-mean((data.test$VALENCE.PLEASANTNESS-test.pred)^2)\n",
    "cat(\"train MSE: \",trainMSE, \"\\n\")\n",
    "cat(\"test MSE: \",testMSE)\n",
    "\n",
    "#summary(basic.lm.fit)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, as predicted, we largely overfit the data when using all predictors for linear regression. Also, consequently to p>>n, a large part of the predictors parameters are NAs. We will use cross validation to try and get the number of predictors that gives the lowest validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidymodels)\n",
    "library(leaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"11487  linear dependencies found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], : NA/NaN/Inf dans un appel à une fonction externe (argument 4)\n",
     "output_type": "error",
     "traceback": [
      "Error in leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], : NA/NaN/Inf dans un appel à une fonction externe (argument 4)\nTraceback:\n",
      "1. regsubsets(VALENCE.PLEASANTNESS ~ ., data, method = \"forward\", \n .     nvmax = 20)",
      "2. regsubsets.formula(VALENCE.PLEASANTNESS ~ ., data, method = \"forward\", \n .     nvmax = 20)",
      "3. leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, \n .     force.out = force.out, intercept = intercept)",
      "4. leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], \n .     force.out[reorder], intercept, nvmax, nbest, warn.dep = FALSE)"
     ]
    }
   ],
   "source": [
    "#testing cell\n",
    "validation.data<-vfold_cv(data, v=5)\n",
    "fit<-regsubsets(VALENCE.PLEASANTNESS~.,data, method=\"forward\", nvmax=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"11519  linear dependencies found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], : NA/NaN/Inf dans un appel à une fonction externe (argument 4)\n",
     "output_type": "error",
     "traceback": [
      "Error in leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], : NA/NaN/Inf dans un appel à une fonction externe (argument 4)\nTraceback:\n",
      "1. sapply(validation.data$splits, cv_fit_and_eval)",
      "2. lapply(X = X, FUN = FUN, ...)",
      "3. FUN(X[[i]], ...)",
      "4. regsubsets(formula, analysis(fold), method = \"forward\", nvmax = 30)   # at line 4 of file <text>",
      "5. regsubsets.formula(formula, analysis(fold), method = \"forward\", \n .     nvmax = 30)",
      "6. leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, \n .     force.out = force.out, intercept = intercept)",
      "7. leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], \n .     force.out[reorder], intercept, nvmax, nbest, warn.dep = FALSE)"
     ]
    }
   ],
   "source": [
    "validation.data<-vfold_cv(data, v=5)\n",
    "\n",
    "cv_fit_and_eval <- function(fold, formula=VALENCE.PLEASANTNESS ~ .) {\n",
    "    fit<-regsubsets(formula, analysis(fold), method=\"forward\", nvmax=30)\n",
    "    validation.set<-assessment(fold)\n",
    "    sapply(seq(1,fit$nvmax-1),\n",
    "           function(idx) fitmean(validation.set$VALENCE.PLEASANTNESS-predict(fit,validation.set,idx,formula)^2))\n",
    "    str(fit)\n",
    "}\n",
    "cv.errors<-sapply(validation.data$splits,cv_fit_and_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"2700  linear dependencies found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    }
   ],
   "source": [
    "fits<-regsubsets(VALENCE.PLEASANTNESS~., data, method = \"forward\", nvmax=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.regsubsets <- function(object, newdata, id, form = as.formula(object$call[[2]])) {\n",
    "    mat = model.matrix(form, newdata)\n",
    "    coefi = coef(object, id=id)\n",
    "    xvars = names(coefi)\n",
    "    mat[,xvars]%*%coefi\n",
    "}                                    #using predict formula defined in Lecture 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"2710  linear dependencies found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"2711  linear dependencies found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"2708  linear dependencies found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"2712  linear dependencies found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"2709  linear dependencies found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 5 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>253.2524</td><td>350.4810</td><td>295.1347</td><td>349.3675</td><td>329.1570</td></tr>\n",
       "\t<tr><td>256.7313</td><td>358.4596</td><td>280.5217</td><td>351.1872</td><td>322.3044</td></tr>\n",
       "\t<tr><td>256.5084</td><td>367.3672</td><td>319.5868</td><td>349.1995</td><td>324.1539</td></tr>\n",
       "\t<tr><td>262.6435</td><td>362.4751</td><td>326.9709</td><td>355.6666</td><td>325.4438</td></tr>\n",
       "\t<tr><td>263.9150</td><td>358.9280</td><td>318.6749</td><td>344.6454</td><td>318.3929</td></tr>\n",
       "\t<tr><td>257.9440</td><td>357.2943</td><td>307.0730</td><td>335.7402</td><td>307.3385</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 5 of type dbl\n",
       "\\begin{tabular}{lllll}\n",
       "\t 253.2524 & 350.4810 & 295.1347 & 349.3675 & 329.1570\\\\\n",
       "\t 256.7313 & 358.4596 & 280.5217 & 351.1872 & 322.3044\\\\\n",
       "\t 256.5084 & 367.3672 & 319.5868 & 349.1995 & 324.1539\\\\\n",
       "\t 262.6435 & 362.4751 & 326.9709 & 355.6666 & 325.4438\\\\\n",
       "\t 263.9150 & 358.9280 & 318.6749 & 344.6454 & 318.3929\\\\\n",
       "\t 257.9440 & 357.2943 & 307.0730 & 335.7402 & 307.3385\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 5 of type dbl\n",
       "\n",
       "| 253.2524 | 350.4810 | 295.1347 | 349.3675 | 329.1570 |\n",
       "| 256.7313 | 358.4596 | 280.5217 | 351.1872 | 322.3044 |\n",
       "| 256.5084 | 367.3672 | 319.5868 | 349.1995 | 324.1539 |\n",
       "| 262.6435 | 362.4751 | 326.9709 | 355.6666 | 325.4438 |\n",
       "| 263.9150 | 358.9280 | 318.6749 | 344.6454 | 318.3929 |\n",
       "| 257.9440 | 357.2943 | 307.0730 | 335.7402 | 307.3385 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     [,2]     [,3]     [,4]     [,5]    \n",
       "[1,] 253.2524 350.4810 295.1347 349.3675 329.1570\n",
       "[2,] 256.7313 358.4596 280.5217 351.1872 322.3044\n",
       "[3,] 256.5084 367.3672 319.5868 349.1995 324.1539\n",
       "[4,] 262.6435 362.4751 326.9709 355.6666 325.4438\n",
       "[5,] 263.9150 358.9280 318.6749 344.6454 318.3929\n",
       "[6,] 257.9440 357.2943 307.0730 335.7402 307.3385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit.and.eval<-function(fold,formula = VALENCE.PLEASANTNESS ~ .) {\n",
    "    fit<-regsubsets(formula, analysis(fold), nvmax=30, method = 'forward')\n",
    "    valid.set<-assessment(fold)\n",
    "    sapply(1:(fit$nvmax-1),\n",
    "          function(nb) mean((valid.set$VALENCE.PLEASANTNESS - predict(fit, valid.set, nb, formula))^2))\n",
    "}\n",
    "validation.data<-vfold_cv(data,v=5)\n",
    "cv.errors<-sapply(validation.data$splits, fit.and.eval)\n",
    "head(cv.errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 10 × 5 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>253.2524</td><td>350.4810</td><td>295.1347</td><td>349.3675</td><td>329.1570</td></tr>\n",
       "\t<tr><td>256.7313</td><td>358.4596</td><td>280.5217</td><td>351.1872</td><td>322.3044</td></tr>\n",
       "\t<tr><td>256.5084</td><td>367.3672</td><td>319.5868</td><td>349.1995</td><td>324.1539</td></tr>\n",
       "\t<tr><td>262.6435</td><td>362.4751</td><td>326.9709</td><td>355.6666</td><td>325.4438</td></tr>\n",
       "\t<tr><td>263.9150</td><td>358.9280</td><td>318.6749</td><td>344.6454</td><td>318.3929</td></tr>\n",
       "\t<tr><td>257.9440</td><td>357.2943</td><td>307.0730</td><td>335.7402</td><td>307.3385</td></tr>\n",
       "\t<tr><td>255.4004</td><td>356.0790</td><td>314.7202</td><td>336.8180</td><td>302.0043</td></tr>\n",
       "\t<tr><td>265.9355</td><td>363.2667</td><td>311.2241</td><td>331.1116</td><td>301.1186</td></tr>\n",
       "\t<tr><td>263.6568</td><td>360.2667</td><td>316.6011</td><td>333.9795</td><td>299.3935</td></tr>\n",
       "\t<tr><td>266.3011</td><td>360.9370</td><td>323.9093</td><td>336.1302</td><td>303.3486</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 10 × 5 of type dbl\n",
       "\\begin{tabular}{lllll}\n",
       "\t 253.2524 & 350.4810 & 295.1347 & 349.3675 & 329.1570\\\\\n",
       "\t 256.7313 & 358.4596 & 280.5217 & 351.1872 & 322.3044\\\\\n",
       "\t 256.5084 & 367.3672 & 319.5868 & 349.1995 & 324.1539\\\\\n",
       "\t 262.6435 & 362.4751 & 326.9709 & 355.6666 & 325.4438\\\\\n",
       "\t 263.9150 & 358.9280 & 318.6749 & 344.6454 & 318.3929\\\\\n",
       "\t 257.9440 & 357.2943 & 307.0730 & 335.7402 & 307.3385\\\\\n",
       "\t 255.4004 & 356.0790 & 314.7202 & 336.8180 & 302.0043\\\\\n",
       "\t 265.9355 & 363.2667 & 311.2241 & 331.1116 & 301.1186\\\\\n",
       "\t 263.6568 & 360.2667 & 316.6011 & 333.9795 & 299.3935\\\\\n",
       "\t 266.3011 & 360.9370 & 323.9093 & 336.1302 & 303.3486\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 10 × 5 of type dbl\n",
       "\n",
       "| 253.2524 | 350.4810 | 295.1347 | 349.3675 | 329.1570 |\n",
       "| 256.7313 | 358.4596 | 280.5217 | 351.1872 | 322.3044 |\n",
       "| 256.5084 | 367.3672 | 319.5868 | 349.1995 | 324.1539 |\n",
       "| 262.6435 | 362.4751 | 326.9709 | 355.6666 | 325.4438 |\n",
       "| 263.9150 | 358.9280 | 318.6749 | 344.6454 | 318.3929 |\n",
       "| 257.9440 | 357.2943 | 307.0730 | 335.7402 | 307.3385 |\n",
       "| 255.4004 | 356.0790 | 314.7202 | 336.8180 | 302.0043 |\n",
       "| 265.9355 | 363.2667 | 311.2241 | 331.1116 | 301.1186 |\n",
       "| 263.6568 | 360.2667 | 316.6011 | 333.9795 | 299.3935 |\n",
       "| 266.3011 | 360.9370 | 323.9093 | 336.1302 | 303.3486 |\n",
       "\n"
      ],
      "text/plain": [
       "      [,1]     [,2]     [,3]     [,4]     [,5]    \n",
       " [1,] 253.2524 350.4810 295.1347 349.3675 329.1570\n",
       " [2,] 256.7313 358.4596 280.5217 351.1872 322.3044\n",
       " [3,] 256.5084 367.3672 319.5868 349.1995 324.1539\n",
       " [4,] 262.6435 362.4751 326.9709 355.6666 325.4438\n",
       " [5,] 263.9150 358.9280 318.6749 344.6454 318.3929\n",
       " [6,] 257.9440 357.2943 307.0730 335.7402 307.3385\n",
       " [7,] 255.4004 356.0790 314.7202 336.8180 302.0043\n",
       " [8,] 265.9355 363.2667 311.2241 331.1116 301.1186\n",
       " [9,] 263.6568 360.2667 316.6011 333.9795 299.3935\n",
       "[10,] 266.3011 360.9370 323.9093 336.1302 303.3486"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "7"
      ],
      "text/latex": [
       "7"
      ],
      "text/markdown": [
       "7"
      ],
      "text/plain": [
       "[1] 7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(cv.errors,10)\n",
    "which.min(rowMeans(cv.errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1931"
      ],
      "text/latex": [
       "1931"
      ],
      "text/markdown": [
       "1931"
      ],
      "text/plain": [
       "[1] 1931"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'character'"
      ],
      "text/latex": [
       "'character'"
      ],
      "text/markdown": [
       "'character'"
      ],
      "text/plain": [
       "[1] \"character\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'87'</li><li>'526'</li><li>'699'</li><li>'1822'</li><li>'2072'</li><li>'2625'</li><li>'3078'</li><li>'8773'</li><li>'8793'</li><li>'10731'</li><li>'10878'</li><li>'11026'</li><li>'11175'</li><li>'11316'</li><li>'11386'</li><li>'12402'</li><li>'12712'</li><li>'16081'</li><li>'21003'</li><li>'24753'</li><li>'26334'</li><li>'29146'</li><li>'30606'</li><li>'38776'</li><li>'39055'</li><li>'40487'</li><li>'41316'</li><li>'41712'</li><li>'43951'</li><li>'44348'</li><li>'44848'</li><li>'45148'</li><li>'45751'</li><li>'46054'</li><li>'46663'</li><li>'46961'</li><li>'47585'</li><li>'47586'</li><li>'47895'</li><li>'48205'</li><li>'49427'</li><li>'50058'</li><li>'51675'</li><li>'52320'</li><li>'57613'</li><li>'57917'</li><li>'58294'</li><li>'59336'</li><li>'62830'</li><li>'63185'</li><li>'64413'</li><li>'67140'</li><li>'67502'</li><li>'67870'</li><li>'71592'</li><li>'71622'</li><li>'73148'</li><li>'73531'</li><li>'73919'</li><li>'74465'</li><li>'74681'</li><li>'75466'</li><li>'75611'</li><li>'76245'</li><li>'77313'</li><li>'77751'</li><li>'77788'</li><li>'78183'</li><li>'78589'</li><li>'82210'</li><li>'83434'</li><li>'83843'</li><li>'84664'</li><li>'85076'</li><li>'85903'</li><li>'86310'</li><li>'87152'</li><li>'87153'</li><li>'87571'</li><li>'87990'</li><li>'89648'</li><li>'90497'</li><li>'95695'</li><li>'97015'</li><li>'97456'</li><li>'98341'</li><li>'99681'</li><li>'100128'</li><li>'100576'</li><li>'102350'</li><li>'103257'</li><li>'107411'</li><li>'107880'</li><li>'109276'</li><li>'109744'</li><li>'110683'</li><li>'111154'</li><li>'112099'</li><li>'114002'</li><li>'114003'</li><li>'114481'</li><li>'114960'</li><li>'116856'</li><li>'117825'</li><li>'118311'</li><li>'118798'</li><li>'119302'</li><li>'119775'</li><li>'121741'</li><li>'122260'</li><li>'122760'</li><li>'123232'</li><li>'123723'</li><li>'124249'</li><li>'124748'</li><li>'125220'</li><li>'125749'</li><li>'126251'</li><li>'126726'</li><li>'127258'</li><li>'127735'</li><li>'128245'</li><li>'129285'</li><li>'129286'</li><li>'129795'</li><li>'130305'</li><li>'130786'</li><li>'131298'</li><li>'131811'</li><li>'132325'</li><li>'132840'</li><li>'133356'</li><li>'138070'</li><li>'138601'</li><li>'140183'</li><li>'140713'</li><li>'141776'</li><li>'142309'</li><li>'143378'</li><li>'144441'</li><li>'145529'</li><li>'146069'</li><li>'146070'</li><li>'146611'</li><li>'148755'</li><li>'149848'</li><li>'150365'</li><li>'154841'</li><li>'155403'</li><li>'156459'</li><li>'157078'</li><li>'157639'</li><li>'158764'</li><li>'159328'</li><li>'160459'</li><li>'161584'</li><li>'162734'</li><li>'163305'</li><li>'163306'</li><li>'163878'</li><li>'165339'</li><li>'165539'</li><li>'166146'</li><li>'166692'</li><li>'167301'</li><li>'172573'</li><li>'173166'</li><li>'174934'</li><li>'175526'</li><li>'176713'</li><li>'177308'</li><li>'178501'</li><li>'180887'</li><li>'180900'</li><li>'181502'</li><li>'182105'</li><li>'184498'</li><li>'185715'</li><li>'186294'</li><li>'187533'</li><li>'191266'</li><li>'191890'</li><li>'193070'</li><li>'193751'</li><li>'194374'</li><li>'194939'</li><li>'195623'</li><li>'196249'</li><li>'196817'</li><li>'197504'</li><li>'198753'</li><li>'200027'</li><li>'200601'</li><li>'200660'</li><li>'200661'</li><li>'201295'</li><li>'203142'</li><li>'203811'</li><li>'204419'</li><li>'205090'</li><li>...</li><li>'1247410'</li><li>'1248990'</li><li>'1250571'</li><li>'1253960'</li><li>'1276003'</li><li>'1279186'</li><li>'1285601'</li><li>'1287205'</li><li>'1298466'</li><li>'1304891'</li><li>'1306507'</li><li>'1308124'</li><li>'1324378'</li><li>'1327606'</li><li>'1329256'</li><li>'1332527'</li><li>'1334156'</li><li>'1335790'</li><li>'1339063'</li><li>'1340692'</li><li>'1342341'</li><li>'1343980'</li><li>'1345620'</li><li>'1347261'</li><li>'1353806'</li><li>'1355452'</li><li>'1357099'</li><li>'1376474'</li><li>'1423799'</li><li>'1653412'</li><li>'1678939'</li><li>'1682606'</li><li>'1695472'</li><li>'1697314'</li><li>'1702846'</li><li>'1704692'</li><li>'1706539'</li><li>'1762444'</li><li>'1764322'</li><li>'1766111'</li><li>'1766201'</li><li>'1773637'</li><li>'1788737'</li><li>'1798207'</li><li>'1811507'</li><li>'1819219'</li><li>'1876894'</li><li>'2069500'</li><li>'2130985'</li><li>'2410078'</li><li>'2414471'</li><li>'2458632'</li><li>'2460817'</li><li>'2465256'</li><li>'2467477'</li><li>'2514401'</li><li>'2518889'</li><li>'2530123'</li><li>'2534625'</li><li>'2554926'</li><li>'2582126'</li><li>'2586674'</li><li>'2643832'</li><li>'2645510'</li><li>'2669196'</li><li>'2673827'</li><li>'2690034'</li><li>'2842821'</li><li>'2847592'</li><li>'2852367'</li><li>'2982781'</li><li>'3004918'</li><li>'3022105'</li><li>'3260181'</li><li>'3262735'</li><li>'3265290'</li><li>'3311451'</li><li>'3314025'</li><li>'3316581'</li><li>'3316600'</li><li>'3319157'</li><li>'3321734'</li><li>'3324312'</li><li>'3326891'</li><li>'3329471'</li><li>'3332052'</li><li>'3334634'</li><li>'3337217'</li><li>'3339801'</li><li>'3342386'</li><li>'3344972'</li><li>'3347559'</li><li>'3350147'</li><li>'3425676'</li><li>'3458303'</li><li>'3460125'</li><li>'3501929'</li><li>'3523133'</li><li>'3528444'</li><li>'3555057'</li><li>'3557724'</li><li>'3560392'</li><li>'3563061'</li><li>'3605896'</li><li>'3611261'</li><li>'3613944'</li><li>'3616634'</li><li>'3619322'</li><li>'3624721'</li><li>'3624819'</li><li>'3632853'</li><li>'3635513'</li><li>'3643556'</li><li>'3646281'</li><li>'3665271'</li><li>'3667897'</li><li>'3686963'</li><li>'3689665'</li><li>'3692395'</li><li>'3695099'</li><li>'3697814'</li><li>'3708639'</li><li>'3711424'</li><li>'3714166'</li><li>'3722329'</li><li>'3725053'</li><li>'3730470'</li><li>'3744206'</li><li>'3746934'</li><li>'3766133'</li><li>'3768857'</li><li>'3771623'</li><li>'3774350'</li><li>'3777098'</li><li>'3788100'</li><li>'3790853'</li><li>'3793626'</li><li>'3801875'</li><li>'3804633'</li><li>'3807404'</li><li>'3846138'</li><li>'3854309'</li><li>'3859859'</li><li>'3873925'</li><li>'3876702'</li><li>'3901776'</li><li>'3924177'</li><li>'3926976'</li><li>'3932608'</li><li>'3935415'</li><li>'3938194'</li><li>'3941003'</li><li>'3946620'</li><li>'3971927'</li><li>'3974779'</li><li>'3977573'</li><li>'3980420'</li><li>'4005865'</li><li>'4062584'</li><li>'4065469'</li><li>'4068284'</li><li>'4076933'</li><li>'4099804'</li><li>'4113918'</li><li>'4139978'</li><li>'4145724'</li><li>'4165861'</li><li>'4171708'</li><li>'4189058'</li><li>'4206305'</li><li>'4220807'</li><li>'4255850'</li><li>'4258781'</li><li>'4261674'</li><li>'4279209'</li><li>'4282135'</li><li>'4290919'</li><li>'4293903'</li><li>'4308514'</li><li>'4320264'</li><li>'4335015'</li><li>'4340874'</li><li>'4361523'</li><li>'4367482'</li><li>'4376295'</li><li>'4385234'</li><li>'4391100'</li><li>'4397029'</li><li>'4405930'</li><li>'4411869'</li><li>'4417812'</li><li>'4423759'</li><li>'4447627'</li><li>'4490667'</li><li>'4501500'</li><li>'4510496'</li><li>'4513510'</li><li>'4516515'</li><li>'4561635'</li><li>'4598028'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '87'\n",
       "\\item '526'\n",
       "\\item '699'\n",
       "\\item '1822'\n",
       "\\item '2072'\n",
       "\\item '2625'\n",
       "\\item '3078'\n",
       "\\item '8773'\n",
       "\\item '8793'\n",
       "\\item '10731'\n",
       "\\item '10878'\n",
       "\\item '11026'\n",
       "\\item '11175'\n",
       "\\item '11316'\n",
       "\\item '11386'\n",
       "\\item '12402'\n",
       "\\item '12712'\n",
       "\\item '16081'\n",
       "\\item '21003'\n",
       "\\item '24753'\n",
       "\\item '26334'\n",
       "\\item '29146'\n",
       "\\item '30606'\n",
       "\\item '38776'\n",
       "\\item '39055'\n",
       "\\item '40487'\n",
       "\\item '41316'\n",
       "\\item '41712'\n",
       "\\item '43951'\n",
       "\\item '44348'\n",
       "\\item '44848'\n",
       "\\item '45148'\n",
       "\\item '45751'\n",
       "\\item '46054'\n",
       "\\item '46663'\n",
       "\\item '46961'\n",
       "\\item '47585'\n",
       "\\item '47586'\n",
       "\\item '47895'\n",
       "\\item '48205'\n",
       "\\item '49427'\n",
       "\\item '50058'\n",
       "\\item '51675'\n",
       "\\item '52320'\n",
       "\\item '57613'\n",
       "\\item '57917'\n",
       "\\item '58294'\n",
       "\\item '59336'\n",
       "\\item '62830'\n",
       "\\item '63185'\n",
       "\\item '64413'\n",
       "\\item '67140'\n",
       "\\item '67502'\n",
       "\\item '67870'\n",
       "\\item '71592'\n",
       "\\item '71622'\n",
       "\\item '73148'\n",
       "\\item '73531'\n",
       "\\item '73919'\n",
       "\\item '74465'\n",
       "\\item '74681'\n",
       "\\item '75466'\n",
       "\\item '75611'\n",
       "\\item '76245'\n",
       "\\item '77313'\n",
       "\\item '77751'\n",
       "\\item '77788'\n",
       "\\item '78183'\n",
       "\\item '78589'\n",
       "\\item '82210'\n",
       "\\item '83434'\n",
       "\\item '83843'\n",
       "\\item '84664'\n",
       "\\item '85076'\n",
       "\\item '85903'\n",
       "\\item '86310'\n",
       "\\item '87152'\n",
       "\\item '87153'\n",
       "\\item '87571'\n",
       "\\item '87990'\n",
       "\\item '89648'\n",
       "\\item '90497'\n",
       "\\item '95695'\n",
       "\\item '97015'\n",
       "\\item '97456'\n",
       "\\item '98341'\n",
       "\\item '99681'\n",
       "\\item '100128'\n",
       "\\item '100576'\n",
       "\\item '102350'\n",
       "\\item '103257'\n",
       "\\item '107411'\n",
       "\\item '107880'\n",
       "\\item '109276'\n",
       "\\item '109744'\n",
       "\\item '110683'\n",
       "\\item '111154'\n",
       "\\item '112099'\n",
       "\\item '114002'\n",
       "\\item '114003'\n",
       "\\item '114481'\n",
       "\\item '114960'\n",
       "\\item '116856'\n",
       "\\item '117825'\n",
       "\\item '118311'\n",
       "\\item '118798'\n",
       "\\item '119302'\n",
       "\\item '119775'\n",
       "\\item '121741'\n",
       "\\item '122260'\n",
       "\\item '122760'\n",
       "\\item '123232'\n",
       "\\item '123723'\n",
       "\\item '124249'\n",
       "\\item '124748'\n",
       "\\item '125220'\n",
       "\\item '125749'\n",
       "\\item '126251'\n",
       "\\item '126726'\n",
       "\\item '127258'\n",
       "\\item '127735'\n",
       "\\item '128245'\n",
       "\\item '129285'\n",
       "\\item '129286'\n",
       "\\item '129795'\n",
       "\\item '130305'\n",
       "\\item '130786'\n",
       "\\item '131298'\n",
       "\\item '131811'\n",
       "\\item '132325'\n",
       "\\item '132840'\n",
       "\\item '133356'\n",
       "\\item '138070'\n",
       "\\item '138601'\n",
       "\\item '140183'\n",
       "\\item '140713'\n",
       "\\item '141776'\n",
       "\\item '142309'\n",
       "\\item '143378'\n",
       "\\item '144441'\n",
       "\\item '145529'\n",
       "\\item '146069'\n",
       "\\item '146070'\n",
       "\\item '146611'\n",
       "\\item '148755'\n",
       "\\item '149848'\n",
       "\\item '150365'\n",
       "\\item '154841'\n",
       "\\item '155403'\n",
       "\\item '156459'\n",
       "\\item '157078'\n",
       "\\item '157639'\n",
       "\\item '158764'\n",
       "\\item '159328'\n",
       "\\item '160459'\n",
       "\\item '161584'\n",
       "\\item '162734'\n",
       "\\item '163305'\n",
       "\\item '163306'\n",
       "\\item '163878'\n",
       "\\item '165339'\n",
       "\\item '165539'\n",
       "\\item '166146'\n",
       "\\item '166692'\n",
       "\\item '167301'\n",
       "\\item '172573'\n",
       "\\item '173166'\n",
       "\\item '174934'\n",
       "\\item '175526'\n",
       "\\item '176713'\n",
       "\\item '177308'\n",
       "\\item '178501'\n",
       "\\item '180887'\n",
       "\\item '180900'\n",
       "\\item '181502'\n",
       "\\item '182105'\n",
       "\\item '184498'\n",
       "\\item '185715'\n",
       "\\item '186294'\n",
       "\\item '187533'\n",
       "\\item '191266'\n",
       "\\item '191890'\n",
       "\\item '193070'\n",
       "\\item '193751'\n",
       "\\item '194374'\n",
       "\\item '194939'\n",
       "\\item '195623'\n",
       "\\item '196249'\n",
       "\\item '196817'\n",
       "\\item '197504'\n",
       "\\item '198753'\n",
       "\\item '200027'\n",
       "\\item '200601'\n",
       "\\item '200660'\n",
       "\\item '200661'\n",
       "\\item '201295'\n",
       "\\item '203142'\n",
       "\\item '203811'\n",
       "\\item '204419'\n",
       "\\item '205090'\n",
       "\\item ...\n",
       "\\item '1247410'\n",
       "\\item '1248990'\n",
       "\\item '1250571'\n",
       "\\item '1253960'\n",
       "\\item '1276003'\n",
       "\\item '1279186'\n",
       "\\item '1285601'\n",
       "\\item '1287205'\n",
       "\\item '1298466'\n",
       "\\item '1304891'\n",
       "\\item '1306507'\n",
       "\\item '1308124'\n",
       "\\item '1324378'\n",
       "\\item '1327606'\n",
       "\\item '1329256'\n",
       "\\item '1332527'\n",
       "\\item '1334156'\n",
       "\\item '1335790'\n",
       "\\item '1339063'\n",
       "\\item '1340692'\n",
       "\\item '1342341'\n",
       "\\item '1343980'\n",
       "\\item '1345620'\n",
       "\\item '1347261'\n",
       "\\item '1353806'\n",
       "\\item '1355452'\n",
       "\\item '1357099'\n",
       "\\item '1376474'\n",
       "\\item '1423799'\n",
       "\\item '1653412'\n",
       "\\item '1678939'\n",
       "\\item '1682606'\n",
       "\\item '1695472'\n",
       "\\item '1697314'\n",
       "\\item '1702846'\n",
       "\\item '1704692'\n",
       "\\item '1706539'\n",
       "\\item '1762444'\n",
       "\\item '1764322'\n",
       "\\item '1766111'\n",
       "\\item '1766201'\n",
       "\\item '1773637'\n",
       "\\item '1788737'\n",
       "\\item '1798207'\n",
       "\\item '1811507'\n",
       "\\item '1819219'\n",
       "\\item '1876894'\n",
       "\\item '2069500'\n",
       "\\item '2130985'\n",
       "\\item '2410078'\n",
       "\\item '2414471'\n",
       "\\item '2458632'\n",
       "\\item '2460817'\n",
       "\\item '2465256'\n",
       "\\item '2467477'\n",
       "\\item '2514401'\n",
       "\\item '2518889'\n",
       "\\item '2530123'\n",
       "\\item '2534625'\n",
       "\\item '2554926'\n",
       "\\item '2582126'\n",
       "\\item '2586674'\n",
       "\\item '2643832'\n",
       "\\item '2645510'\n",
       "\\item '2669196'\n",
       "\\item '2673827'\n",
       "\\item '2690034'\n",
       "\\item '2842821'\n",
       "\\item '2847592'\n",
       "\\item '2852367'\n",
       "\\item '2982781'\n",
       "\\item '3004918'\n",
       "\\item '3022105'\n",
       "\\item '3260181'\n",
       "\\item '3262735'\n",
       "\\item '3265290'\n",
       "\\item '3311451'\n",
       "\\item '3314025'\n",
       "\\item '3316581'\n",
       "\\item '3316600'\n",
       "\\item '3319157'\n",
       "\\item '3321734'\n",
       "\\item '3324312'\n",
       "\\item '3326891'\n",
       "\\item '3329471'\n",
       "\\item '3332052'\n",
       "\\item '3334634'\n",
       "\\item '3337217'\n",
       "\\item '3339801'\n",
       "\\item '3342386'\n",
       "\\item '3344972'\n",
       "\\item '3347559'\n",
       "\\item '3350147'\n",
       "\\item '3425676'\n",
       "\\item '3458303'\n",
       "\\item '3460125'\n",
       "\\item '3501929'\n",
       "\\item '3523133'\n",
       "\\item '3528444'\n",
       "\\item '3555057'\n",
       "\\item '3557724'\n",
       "\\item '3560392'\n",
       "\\item '3563061'\n",
       "\\item '3605896'\n",
       "\\item '3611261'\n",
       "\\item '3613944'\n",
       "\\item '3616634'\n",
       "\\item '3619322'\n",
       "\\item '3624721'\n",
       "\\item '3624819'\n",
       "\\item '3632853'\n",
       "\\item '3635513'\n",
       "\\item '3643556'\n",
       "\\item '3646281'\n",
       "\\item '3665271'\n",
       "\\item '3667897'\n",
       "\\item '3686963'\n",
       "\\item '3689665'\n",
       "\\item '3692395'\n",
       "\\item '3695099'\n",
       "\\item '3697814'\n",
       "\\item '3708639'\n",
       "\\item '3711424'\n",
       "\\item '3714166'\n",
       "\\item '3722329'\n",
       "\\item '3725053'\n",
       "\\item '3730470'\n",
       "\\item '3744206'\n",
       "\\item '3746934'\n",
       "\\item '3766133'\n",
       "\\item '3768857'\n",
       "\\item '3771623'\n",
       "\\item '3774350'\n",
       "\\item '3777098'\n",
       "\\item '3788100'\n",
       "\\item '3790853'\n",
       "\\item '3793626'\n",
       "\\item '3801875'\n",
       "\\item '3804633'\n",
       "\\item '3807404'\n",
       "\\item '3846138'\n",
       "\\item '3854309'\n",
       "\\item '3859859'\n",
       "\\item '3873925'\n",
       "\\item '3876702'\n",
       "\\item '3901776'\n",
       "\\item '3924177'\n",
       "\\item '3926976'\n",
       "\\item '3932608'\n",
       "\\item '3935415'\n",
       "\\item '3938194'\n",
       "\\item '3941003'\n",
       "\\item '3946620'\n",
       "\\item '3971927'\n",
       "\\item '3974779'\n",
       "\\item '3977573'\n",
       "\\item '3980420'\n",
       "\\item '4005865'\n",
       "\\item '4062584'\n",
       "\\item '4065469'\n",
       "\\item '4068284'\n",
       "\\item '4076933'\n",
       "\\item '4099804'\n",
       "\\item '4113918'\n",
       "\\item '4139978'\n",
       "\\item '4145724'\n",
       "\\item '4165861'\n",
       "\\item '4171708'\n",
       "\\item '4189058'\n",
       "\\item '4206305'\n",
       "\\item '4220807'\n",
       "\\item '4255850'\n",
       "\\item '4258781'\n",
       "\\item '4261674'\n",
       "\\item '4279209'\n",
       "\\item '4282135'\n",
       "\\item '4290919'\n",
       "\\item '4293903'\n",
       "\\item '4308514'\n",
       "\\item '4320264'\n",
       "\\item '4335015'\n",
       "\\item '4340874'\n",
       "\\item '4361523'\n",
       "\\item '4367482'\n",
       "\\item '4376295'\n",
       "\\item '4385234'\n",
       "\\item '4391100'\n",
       "\\item '4397029'\n",
       "\\item '4405930'\n",
       "\\item '4411869'\n",
       "\\item '4417812'\n",
       "\\item '4423759'\n",
       "\\item '4447627'\n",
       "\\item '4490667'\n",
       "\\item '4501500'\n",
       "\\item '4510496'\n",
       "\\item '4513510'\n",
       "\\item '4516515'\n",
       "\\item '4561635'\n",
       "\\item '4598028'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '87'\n",
       "2. '526'\n",
       "3. '699'\n",
       "4. '1822'\n",
       "5. '2072'\n",
       "6. '2625'\n",
       "7. '3078'\n",
       "8. '8773'\n",
       "9. '8793'\n",
       "10. '10731'\n",
       "11. '10878'\n",
       "12. '11026'\n",
       "13. '11175'\n",
       "14. '11316'\n",
       "15. '11386'\n",
       "16. '12402'\n",
       "17. '12712'\n",
       "18. '16081'\n",
       "19. '21003'\n",
       "20. '24753'\n",
       "21. '26334'\n",
       "22. '29146'\n",
       "23. '30606'\n",
       "24. '38776'\n",
       "25. '39055'\n",
       "26. '40487'\n",
       "27. '41316'\n",
       "28. '41712'\n",
       "29. '43951'\n",
       "30. '44348'\n",
       "31. '44848'\n",
       "32. '45148'\n",
       "33. '45751'\n",
       "34. '46054'\n",
       "35. '46663'\n",
       "36. '46961'\n",
       "37. '47585'\n",
       "38. '47586'\n",
       "39. '47895'\n",
       "40. '48205'\n",
       "41. '49427'\n",
       "42. '50058'\n",
       "43. '51675'\n",
       "44. '52320'\n",
       "45. '57613'\n",
       "46. '57917'\n",
       "47. '58294'\n",
       "48. '59336'\n",
       "49. '62830'\n",
       "50. '63185'\n",
       "51. '64413'\n",
       "52. '67140'\n",
       "53. '67502'\n",
       "54. '67870'\n",
       "55. '71592'\n",
       "56. '71622'\n",
       "57. '73148'\n",
       "58. '73531'\n",
       "59. '73919'\n",
       "60. '74465'\n",
       "61. '74681'\n",
       "62. '75466'\n",
       "63. '75611'\n",
       "64. '76245'\n",
       "65. '77313'\n",
       "66. '77751'\n",
       "67. '77788'\n",
       "68. '78183'\n",
       "69. '78589'\n",
       "70. '82210'\n",
       "71. '83434'\n",
       "72. '83843'\n",
       "73. '84664'\n",
       "74. '85076'\n",
       "75. '85903'\n",
       "76. '86310'\n",
       "77. '87152'\n",
       "78. '87153'\n",
       "79. '87571'\n",
       "80. '87990'\n",
       "81. '89648'\n",
       "82. '90497'\n",
       "83. '95695'\n",
       "84. '97015'\n",
       "85. '97456'\n",
       "86. '98341'\n",
       "87. '99681'\n",
       "88. '100128'\n",
       "89. '100576'\n",
       "90. '102350'\n",
       "91. '103257'\n",
       "92. '107411'\n",
       "93. '107880'\n",
       "94. '109276'\n",
       "95. '109744'\n",
       "96. '110683'\n",
       "97. '111154'\n",
       "98. '112099'\n",
       "99. '114002'\n",
       "100. '114003'\n",
       "101. '114481'\n",
       "102. '114960'\n",
       "103. '116856'\n",
       "104. '117825'\n",
       "105. '118311'\n",
       "106. '118798'\n",
       "107. '119302'\n",
       "108. '119775'\n",
       "109. '121741'\n",
       "110. '122260'\n",
       "111. '122760'\n",
       "112. '123232'\n",
       "113. '123723'\n",
       "114. '124249'\n",
       "115. '124748'\n",
       "116. '125220'\n",
       "117. '125749'\n",
       "118. '126251'\n",
       "119. '126726'\n",
       "120. '127258'\n",
       "121. '127735'\n",
       "122. '128245'\n",
       "123. '129285'\n",
       "124. '129286'\n",
       "125. '129795'\n",
       "126. '130305'\n",
       "127. '130786'\n",
       "128. '131298'\n",
       "129. '131811'\n",
       "130. '132325'\n",
       "131. '132840'\n",
       "132. '133356'\n",
       "133. '138070'\n",
       "134. '138601'\n",
       "135. '140183'\n",
       "136. '140713'\n",
       "137. '141776'\n",
       "138. '142309'\n",
       "139. '143378'\n",
       "140. '144441'\n",
       "141. '145529'\n",
       "142. '146069'\n",
       "143. '146070'\n",
       "144. '146611'\n",
       "145. '148755'\n",
       "146. '149848'\n",
       "147. '150365'\n",
       "148. '154841'\n",
       "149. '155403'\n",
       "150. '156459'\n",
       "151. '157078'\n",
       "152. '157639'\n",
       "153. '158764'\n",
       "154. '159328'\n",
       "155. '160459'\n",
       "156. '161584'\n",
       "157. '162734'\n",
       "158. '163305'\n",
       "159. '163306'\n",
       "160. '163878'\n",
       "161. '165339'\n",
       "162. '165539'\n",
       "163. '166146'\n",
       "164. '166692'\n",
       "165. '167301'\n",
       "166. '172573'\n",
       "167. '173166'\n",
       "168. '174934'\n",
       "169. '175526'\n",
       "170. '176713'\n",
       "171. '177308'\n",
       "172. '178501'\n",
       "173. '180887'\n",
       "174. '180900'\n",
       "175. '181502'\n",
       "176. '182105'\n",
       "177. '184498'\n",
       "178. '185715'\n",
       "179. '186294'\n",
       "180. '187533'\n",
       "181. '191266'\n",
       "182. '191890'\n",
       "183. '193070'\n",
       "184. '193751'\n",
       "185. '194374'\n",
       "186. '194939'\n",
       "187. '195623'\n",
       "188. '196249'\n",
       "189. '196817'\n",
       "190. '197504'\n",
       "191. '198753'\n",
       "192. '200027'\n",
       "193. '200601'\n",
       "194. '200660'\n",
       "195. '200661'\n",
       "196. '201295'\n",
       "197. '203142'\n",
       "198. '203811'\n",
       "199. '204419'\n",
       "200. '205090'\n",
       "201. ...\n",
       "202. '1247410'\n",
       "203. '1248990'\n",
       "204. '1250571'\n",
       "205. '1253960'\n",
       "206. '1276003'\n",
       "207. '1279186'\n",
       "208. '1285601'\n",
       "209. '1287205'\n",
       "210. '1298466'\n",
       "211. '1304891'\n",
       "212. '1306507'\n",
       "213. '1308124'\n",
       "214. '1324378'\n",
       "215. '1327606'\n",
       "216. '1329256'\n",
       "217. '1332527'\n",
       "218. '1334156'\n",
       "219. '1335790'\n",
       "220. '1339063'\n",
       "221. '1340692'\n",
       "222. '1342341'\n",
       "223. '1343980'\n",
       "224. '1345620'\n",
       "225. '1347261'\n",
       "226. '1353806'\n",
       "227. '1355452'\n",
       "228. '1357099'\n",
       "229. '1376474'\n",
       "230. '1423799'\n",
       "231. '1653412'\n",
       "232. '1678939'\n",
       "233. '1682606'\n",
       "234. '1695472'\n",
       "235. '1697314'\n",
       "236. '1702846'\n",
       "237. '1704692'\n",
       "238. '1706539'\n",
       "239. '1762444'\n",
       "240. '1764322'\n",
       "241. '1766111'\n",
       "242. '1766201'\n",
       "243. '1773637'\n",
       "244. '1788737'\n",
       "245. '1798207'\n",
       "246. '1811507'\n",
       "247. '1819219'\n",
       "248. '1876894'\n",
       "249. '2069500'\n",
       "250. '2130985'\n",
       "251. '2410078'\n",
       "252. '2414471'\n",
       "253. '2458632'\n",
       "254. '2460817'\n",
       "255. '2465256'\n",
       "256. '2467477'\n",
       "257. '2514401'\n",
       "258. '2518889'\n",
       "259. '2530123'\n",
       "260. '2534625'\n",
       "261. '2554926'\n",
       "262. '2582126'\n",
       "263. '2586674'\n",
       "264. '2643832'\n",
       "265. '2645510'\n",
       "266. '2669196'\n",
       "267. '2673827'\n",
       "268. '2690034'\n",
       "269. '2842821'\n",
       "270. '2847592'\n",
       "271. '2852367'\n",
       "272. '2982781'\n",
       "273. '3004918'\n",
       "274. '3022105'\n",
       "275. '3260181'\n",
       "276. '3262735'\n",
       "277. '3265290'\n",
       "278. '3311451'\n",
       "279. '3314025'\n",
       "280. '3316581'\n",
       "281. '3316600'\n",
       "282. '3319157'\n",
       "283. '3321734'\n",
       "284. '3324312'\n",
       "285. '3326891'\n",
       "286. '3329471'\n",
       "287. '3332052'\n",
       "288. '3334634'\n",
       "289. '3337217'\n",
       "290. '3339801'\n",
       "291. '3342386'\n",
       "292. '3344972'\n",
       "293. '3347559'\n",
       "294. '3350147'\n",
       "295. '3425676'\n",
       "296. '3458303'\n",
       "297. '3460125'\n",
       "298. '3501929'\n",
       "299. '3523133'\n",
       "300. '3528444'\n",
       "301. '3555057'\n",
       "302. '3557724'\n",
       "303. '3560392'\n",
       "304. '3563061'\n",
       "305. '3605896'\n",
       "306. '3611261'\n",
       "307. '3613944'\n",
       "308. '3616634'\n",
       "309. '3619322'\n",
       "310. '3624721'\n",
       "311. '3624819'\n",
       "312. '3632853'\n",
       "313. '3635513'\n",
       "314. '3643556'\n",
       "315. '3646281'\n",
       "316. '3665271'\n",
       "317. '3667897'\n",
       "318. '3686963'\n",
       "319. '3689665'\n",
       "320. '3692395'\n",
       "321. '3695099'\n",
       "322. '3697814'\n",
       "323. '3708639'\n",
       "324. '3711424'\n",
       "325. '3714166'\n",
       "326. '3722329'\n",
       "327. '3725053'\n",
       "328. '3730470'\n",
       "329. '3744206'\n",
       "330. '3746934'\n",
       "331. '3766133'\n",
       "332. '3768857'\n",
       "333. '3771623'\n",
       "334. '3774350'\n",
       "335. '3777098'\n",
       "336. '3788100'\n",
       "337. '3790853'\n",
       "338. '3793626'\n",
       "339. '3801875'\n",
       "340. '3804633'\n",
       "341. '3807404'\n",
       "342. '3846138'\n",
       "343. '3854309'\n",
       "344. '3859859'\n",
       "345. '3873925'\n",
       "346. '3876702'\n",
       "347. '3901776'\n",
       "348. '3924177'\n",
       "349. '3926976'\n",
       "350. '3932608'\n",
       "351. '3935415'\n",
       "352. '3938194'\n",
       "353. '3941003'\n",
       "354. '3946620'\n",
       "355. '3971927'\n",
       "356. '3974779'\n",
       "357. '3977573'\n",
       "358. '3980420'\n",
       "359. '4005865'\n",
       "360. '4062584'\n",
       "361. '4065469'\n",
       "362. '4068284'\n",
       "363. '4076933'\n",
       "364. '4099804'\n",
       "365. '4113918'\n",
       "366. '4139978'\n",
       "367. '4145724'\n",
       "368. '4165861'\n",
       "369. '4171708'\n",
       "370. '4189058'\n",
       "371. '4206305'\n",
       "372. '4220807'\n",
       "373. '4255850'\n",
       "374. '4258781'\n",
       "375. '4261674'\n",
       "376. '4279209'\n",
       "377. '4282135'\n",
       "378. '4290919'\n",
       "379. '4293903'\n",
       "380. '4308514'\n",
       "381. '4320264'\n",
       "382. '4335015'\n",
       "383. '4340874'\n",
       "384. '4361523'\n",
       "385. '4367482'\n",
       "386. '4376295'\n",
       "387. '4385234'\n",
       "388. '4391100'\n",
       "389. '4397029'\n",
       "390. '4405930'\n",
       "391. '4411869'\n",
       "392. '4417812'\n",
       "393. '4423759'\n",
       "394. '4447627'\n",
       "395. '4490667'\n",
       "396. '4501500'\n",
       "397. '4510496'\n",
       "398. '4513510'\n",
       "399. '4516515'\n",
       "400. '4561635'\n",
       "401. '4598028'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] \"87\"      \"526\"     \"699\"     \"1822\"    \"2072\"    \"2625\"    \"3078\"   \n",
       "  [8] \"8773\"    \"8793\"    \"10731\"   \"10878\"   \"11026\"   \"11175\"   \"11316\"  \n",
       " [15] \"11386\"   \"12402\"   \"12712\"   \"16081\"   \"21003\"   \"24753\"   \"26334\"  \n",
       " [22] \"29146\"   \"30606\"   \"38776\"   \"39055\"   \"40487\"   \"41316\"   \"41712\"  \n",
       " [29] \"43951\"   \"44348\"   \"44848\"   \"45148\"   \"45751\"   \"46054\"   \"46663\"  \n",
       " [36] \"46961\"   \"47585\"   \"47586\"   \"47895\"   \"48205\"   \"49427\"   \"50058\"  \n",
       " [43] \"51675\"   \"52320\"   \"57613\"   \"57917\"   \"58294\"   \"59336\"   \"62830\"  \n",
       " [50] \"63185\"   \"64413\"   \"67140\"   \"67502\"   \"67870\"   \"71592\"   \"71622\"  \n",
       " [57] \"73148\"   \"73531\"   \"73919\"   \"74465\"   \"74681\"   \"75466\"   \"75611\"  \n",
       " [64] \"76245\"   \"77313\"   \"77751\"   \"77788\"   \"78183\"   \"78589\"   \"82210\"  \n",
       " [71] \"83434\"   \"83843\"   \"84664\"   \"85076\"   \"85903\"   \"86310\"   \"87152\"  \n",
       " [78] \"87153\"   \"87571\"   \"87990\"   \"89648\"   \"90497\"   \"95695\"   \"97015\"  \n",
       " [85] \"97456\"   \"98341\"   \"99681\"   \"100128\"  \"100576\"  \"102350\"  \"103257\" \n",
       " [92] \"107411\"  \"107880\"  \"109276\"  \"109744\"  \"110683\"  \"111154\"  \"112099\" \n",
       " [99] \"114002\"  \"114003\"  \"114481\"  \"114960\"  \"116856\"  \"117825\"  \"118311\" \n",
       "[106] \"118798\"  \"119302\"  \"119775\"  \"121741\"  \"122260\"  \"122760\"  \"123232\" \n",
       "[113] \"123723\"  \"124249\"  \"124748\"  \"125220\"  \"125749\"  \"126251\"  \"126726\" \n",
       "[120] \"127258\"  \"127735\"  \"128245\"  \"129285\"  \"129286\"  \"129795\"  \"130305\" \n",
       "[127] \"130786\"  \"131298\"  \"131811\"  \"132325\"  \"132840\"  \"133356\"  \"138070\" \n",
       "[134] \"138601\"  \"140183\"  \"140713\"  \"141776\"  \"142309\"  \"143378\"  \"144441\" \n",
       "[141] \"145529\"  \"146069\"  \"146070\"  \"146611\"  \"148755\"  \"149848\"  \"150365\" \n",
       "[148] \"154841\"  \"155403\"  \"156459\"  \"157078\"  \"157639\"  \"158764\"  \"159328\" \n",
       "[155] \"160459\"  \"161584\"  \"162734\"  \"163305\"  \"163306\"  \"163878\"  \"165339\" \n",
       "[162] \"165539\"  \"166146\"  \"166692\"  \"167301\"  \"172573\"  \"173166\"  \"174934\" \n",
       "[169] \"175526\"  \"176713\"  \"177308\"  \"178501\"  \"180887\"  \"180900\"  \"181502\" \n",
       "[176] \"182105\"  \"184498\"  \"185715\"  \"186294\"  \"187533\"  \"191266\"  \"191890\" \n",
       "[183] \"193070\"  \"193751\"  \"194374\"  \"194939\"  \"195623\"  \"196249\"  \"196817\" \n",
       "[190] \"197504\"  \"198753\"  \"200027\"  \"200601\"  \"200660\"  \"200661\"  \"201295\" \n",
       "[197] \"203142\"  \"203811\"  \"204419\"  \"205090\"  \"223417\"  \"223842\"  \"224756\" \n",
       "[204] \"228422\"  \"228797\"  \"232192\"  \"232211\"  \"236320\"  \"239084\"  \"243922\" \n",
       "[211] \"244621\"  \"245332\"  \"249542\"  \"255226\"  \"255941\"  \"260279\"  \"264569\" \n",
       "[218] \"265327\"  \"266056\"  \"266786\"  \"269686\"  \"271187\"  \"274901\"  \"277856\" \n",
       "[225] \"287632\"  \"288391\"  \"289162\"  \"289882\"  \"290644\"  \"292171\"  \"293732\" \n",
       "[232] \"294469\"  \"295237\"  \"296006\"  \"297547\"  \"299092\"  \"299866\"  \"300671\" \n",
       "[239] \"301387\"  \"301417\"  \"302194\"  \"304531\"  \"305369\"  \"309232\"  \"310019\" \n",
       "[246] \"310837\"  \"311626\"  \"312416\"  \"318927\"  \"319600\"  \"334942\"  \"335761\" \n",
       "[253] \"336581\"  \"412679\"  \"660713\"  \"662972\"  \"666432\"  \"667587\"  \"671052\" \n",
       "[260] \"672217\"  \"673373\"  \"674534\"  \"675696\"  \"676849\"  \"680353\"  \"682688\" \n",
       "[267] \"755806\"  \"768171\"  \"771480\"  \"783117\"  \"784369\"  \"785630\"  \"786884\" \n",
       "[274] \"788139\"  \"789395\"  \"790652\"  \"791910\"  \"792072\"  \"792244\"  \"802010\" \n",
       "[281] \"804545\"  \"805814\"  \"807084\"  \"808355\"  \"809627\"  \"817276\"  \"817280\" \n",
       "[288] \"818559\"  \"819839\"  \"821120\"  \"822402\"  \"823685\"  \"824969\"  \"826254\" \n",
       "[295] \"827540\"  \"827712\"  \"837864\"  \"839159\"  \"840455\"  \"841752\"  \"843050\" \n",
       "[302] \"844349\"  \"845649\"  \"853470\"  \"854777\"  \"856085\"  \"857394\"  \"858704\" \n",
       "[309] \"860015\"  \"861327\"  \"862640\"  \"863954\"  \"874502\"  \"877149\"  \"878474\" \n",
       "[316] \"879800\"  \"881127\"  \"882455\"  \"885059\"  \"890445\"  \"891780\"  \"893116\" \n",
       "[323] \"894453\"  \"895791\"  \"897130\"  \"898470\"  \"899811\"  \"901153\"  \"910575\" \n",
       "[330] \"911772\"  \"932132\"  \"952717\"  \"959771\"  \"961157\"  \"962544\"  \"963932\" \n",
       "[337] \"965321\"  \"966711\"  \"968102\"  \"969494\"  \"970887\"  \"972281\"  \"973676\" \n",
       "[344] \"975072\"  \"976469\"  \"977867\"  \"979266\"  \"980666\"  \"982067\"  \"983469\" \n",
       "[351] \"984872\"  \"986276\"  \"987681\"  \"989087\"  \"990494\"  \"991902\"  \"993311\" \n",
       "[358] \"994721\"  \"996132\"  \"997544\"  \"998957\"  \"1000371\" \"1001786\" \"1003202\"\n",
       "[365] \"1004619\" \"1006037\" \"1007456\" \"1022947\" \"1044507\" \"1060637\" \"1062094\"\n",
       "[372] \"1063552\" \"1065011\" \"1066292\" \"1088302\" \"1110537\" \"1132997\" \"1198919\"\n",
       "[379] \"1200468\" \"1203569\" \"1205121\" \"1206674\" \"1226956\" \"1228528\" \"1230088\"\n",
       "[386] \"1233233\" \"1234804\" \"1237949\" \"1239523\" \"1242674\" \"1244242\" \"1247409\"\n",
       "[393] \"1247410\" \"1248990\" \"1250571\" \"1253960\" \"1276003\" \"1279186\" \"1285601\"\n",
       "[400] \"1287205\" \"1298466\" \"1304891\" \"1306507\" \"1308124\" \"1324378\" \"1327606\"\n",
       "[407] \"1329256\" \"1332527\" \"1334156\" \"1335790\" \"1339063\" \"1340692\" \"1342341\"\n",
       "[414] \"1343980\" \"1345620\" \"1347261\" \"1353806\" \"1355452\" \"1357099\" \"1376474\"\n",
       "[421] \"1423799\" \"1653412\" \"1678939\" \"1682606\" \"1695472\" \"1697314\" \"1702846\"\n",
       "[428] \"1704692\" \"1706539\" \"1762444\" \"1764322\" \"1766111\" \"1766201\" \"1773637\"\n",
       "[435] \"1788737\" \"1798207\" \"1811507\" \"1819219\" \"1876894\" \"2069500\" \"2130985\"\n",
       "[442] \"2410078\" \"2414471\" \"2458632\" \"2460817\" \"2465256\" \"2467477\" \"2514401\"\n",
       "[449] \"2518889\" \"2530123\" \"2534625\" \"2554926\" \"2582126\" \"2586674\" \"2643832\"\n",
       "[456] \"2645510\" \"2669196\" \"2673827\" \"2690034\" \"2842821\" \"2847592\" \"2852367\"\n",
       "[463] \"2982781\" \"3004918\" \"3022105\" \"3260181\" \"3262735\" \"3265290\" \"3311451\"\n",
       "[470] \"3314025\" \"3316581\" \"3316600\" \"3319157\" \"3321734\" \"3324312\" \"3326891\"\n",
       "[477] \"3329471\" \"3332052\" \"3334634\" \"3337217\" \"3339801\" \"3342386\" \"3344972\"\n",
       "[484] \"3347559\" \"3350147\" \"3425676\" \"3458303\" \"3460125\" \"3501929\" \"3523133\"\n",
       "[491] \"3528444\" \"3555057\" \"3557724\" \"3560392\" \"3563061\" \"3605896\" \"3611261\"\n",
       "[498] \"3613944\" \"3616634\" \"3619322\" \"3624721\" \"3624819\" \"3632853\" \"3635513\"\n",
       "[505] \"3643556\" \"3646281\" \"3665271\" \"3667897\" \"3686963\" \"3689665\" \"3692395\"\n",
       "[512] \"3695099\" \"3697814\" \"3708639\" \"3711424\" \"3714166\" \"3722329\" \"3725053\"\n",
       "[519] \"3730470\" \"3744206\" \"3746934\" \"3766133\" \"3768857\" \"3771623\" \"3774350\"\n",
       "[526] \"3777098\" \"3788100\" \"3790853\" \"3793626\" \"3801875\" \"3804633\" \"3807404\"\n",
       "[533] \"3846138\" \"3854309\" \"3859859\" \"3873925\" \"3876702\" \"3901776\" \"3924177\"\n",
       "[540] \"3926976\" \"3932608\" \"3935415\" \"3938194\" \"3941003\" \"3946620\" \"3971927\"\n",
       "[547] \"3974779\" \"3977573\" \"3980420\" \"4005865\" \"4062584\" \"4065469\" \"4068284\"\n",
       "[554] \"4076933\" \"4099804\" \"4113918\" \"4139978\" \"4145724\" \"4165861\" \"4171708\"\n",
       "[561] \"4189058\" \"4206305\" \"4220807\" \"4255850\" \"4258781\" \"4261674\" \"4279209\"\n",
       "[568] \"4282135\" \"4290919\" \"4293903\" \"4308514\" \"4320264\" \"4335015\" \"4340874\"\n",
       "[575] \"4361523\" \"4367482\" \"4376295\" \"4385234\" \"4391100\" \"4397029\" \"4405930\"\n",
       "[582] \"4411869\" \"4417812\" \"4423759\" \"4447627\" \"4490667\" \"4501500\" \"4510496\"\n",
       "[589] \"4513510\" \"4516515\" \"4561635\" \"4598028\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred.to.rm<-apply(max.cor.pred,1,function(x) x[1])\n",
    "length(pred.to.rm)\n",
    "pred.to.rm<-pred.to.rm[!duplicated(pred.to.rm)]\n",
    "typeof(pred.to.rm)\n",
    "pred.to.rm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "dense_input (Dense)                 (None, 10)                      18560       \n",
      "________________________________________________________________________________\n",
      "dense_2 (Dense)                     (None, 20)                      220         \n",
      "________________________________________________________________________________\n",
      "dense_output (Dense)                (None, 1)                       21          \n",
      "================================================================================\n",
      "Total params: 18,801\n",
      "Trainable params: 18,801\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn1<-keras_model_sequential()\n",
    "nn1 %>%\n",
    "    layer_dense(units=10, activation='relu', input_shape = c(1855), name = 'dense_input') %>%\n",
    "    layer_dense(units=20, activation='relu',name = 'dense_2') %>%\n",
    "    layer_dense(units=1, activation='linear', name = 'dense_output')\n",
    "summary(nn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2 %>% compile(loss='MSE',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2 %>% fit(as.matrix(data[,-1]),\n",
    "                    data[,1],\n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred<-predict(nn2,as.matrix(data.final.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.sub<-cbind(which(pred==pred),pred)\n",
    "colnames(pred.sub)<-c(\"id\",\"VALENCE.PLEASANTNESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 20 × 2 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>id</th><th scope=col>VALENCE.PLEASANTNESS</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>38.73025</td></tr>\n",
       "\t<tr><td> 2</td><td>67.88890</td></tr>\n",
       "\t<tr><td> 3</td><td>45.65573</td></tr>\n",
       "\t<tr><td> 4</td><td>49.46078</td></tr>\n",
       "\t<tr><td> 5</td><td>36.78001</td></tr>\n",
       "\t<tr><td> 6</td><td>56.23206</td></tr>\n",
       "\t<tr><td> 7</td><td>39.44513</td></tr>\n",
       "\t<tr><td> 8</td><td>55.63501</td></tr>\n",
       "\t<tr><td> 9</td><td>46.92269</td></tr>\n",
       "\t<tr><td>10</td><td>54.15268</td></tr>\n",
       "\t<tr><td>11</td><td>23.84252</td></tr>\n",
       "\t<tr><td>12</td><td>51.45921</td></tr>\n",
       "\t<tr><td>13</td><td>37.71709</td></tr>\n",
       "\t<tr><td>14</td><td>42.82154</td></tr>\n",
       "\t<tr><td>15</td><td>52.00062</td></tr>\n",
       "\t<tr><td>16</td><td>48.10979</td></tr>\n",
       "\t<tr><td>17</td><td>44.53265</td></tr>\n",
       "\t<tr><td>18</td><td>54.15979</td></tr>\n",
       "\t<tr><td>19</td><td>37.43641</td></tr>\n",
       "\t<tr><td>20</td><td>65.32730</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 20 × 2 of type dbl\n",
       "\\begin{tabular}{ll}\n",
       " id & VALENCE.PLEASANTNESS\\\\\n",
       "\\hline\n",
       "\t  1 & 38.73025\\\\\n",
       "\t  2 & 67.88890\\\\\n",
       "\t  3 & 45.65573\\\\\n",
       "\t  4 & 49.46078\\\\\n",
       "\t  5 & 36.78001\\\\\n",
       "\t  6 & 56.23206\\\\\n",
       "\t  7 & 39.44513\\\\\n",
       "\t  8 & 55.63501\\\\\n",
       "\t  9 & 46.92269\\\\\n",
       "\t 10 & 54.15268\\\\\n",
       "\t 11 & 23.84252\\\\\n",
       "\t 12 & 51.45921\\\\\n",
       "\t 13 & 37.71709\\\\\n",
       "\t 14 & 42.82154\\\\\n",
       "\t 15 & 52.00062\\\\\n",
       "\t 16 & 48.10979\\\\\n",
       "\t 17 & 44.53265\\\\\n",
       "\t 18 & 54.15979\\\\\n",
       "\t 19 & 37.43641\\\\\n",
       "\t 20 & 65.32730\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 20 × 2 of type dbl\n",
       "\n",
       "| id | VALENCE.PLEASANTNESS |\n",
       "|---|---|\n",
       "|  1 | 38.73025 |\n",
       "|  2 | 67.88890 |\n",
       "|  3 | 45.65573 |\n",
       "|  4 | 49.46078 |\n",
       "|  5 | 36.78001 |\n",
       "|  6 | 56.23206 |\n",
       "|  7 | 39.44513 |\n",
       "|  8 | 55.63501 |\n",
       "|  9 | 46.92269 |\n",
       "| 10 | 54.15268 |\n",
       "| 11 | 23.84252 |\n",
       "| 12 | 51.45921 |\n",
       "| 13 | 37.71709 |\n",
       "| 14 | 42.82154 |\n",
       "| 15 | 52.00062 |\n",
       "| 16 | 48.10979 |\n",
       "| 17 | 44.53265 |\n",
       "| 18 | 54.15979 |\n",
       "| 19 | 37.43641 |\n",
       "| 20 | 65.32730 |\n",
       "\n"
      ],
      "text/plain": [
       "      id VALENCE.PLEASANTNESS\n",
       " [1,]  1 38.73025            \n",
       " [2,]  2 67.88890            \n",
       " [3,]  3 45.65573            \n",
       " [4,]  4 49.46078            \n",
       " [5,]  5 36.78001            \n",
       " [6,]  6 56.23206            \n",
       " [7,]  7 39.44513            \n",
       " [8,]  8 55.63501            \n",
       " [9,]  9 46.92269            \n",
       "[10,] 10 54.15268            \n",
       "[11,] 11 23.84252            \n",
       "[12,] 12 51.45921            \n",
       "[13,] 13 37.71709            \n",
       "[14,] 14 42.82154            \n",
       "[15,] 15 52.00062            \n",
       "[16,] 16 48.10979            \n",
       "[17,] 17 44.53265            \n",
       "[18,] 18 54.15979            \n",
       "[19,] 19 37.43641            \n",
       "[20,] 20 65.32730            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(pred.sub,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(pred.sub,\"submisson_nn_10_10_1.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "dense_input (Dense)                 (None, 10)                      18560       \n",
      "________________________________________________________________________________\n",
      "dense_2 (Dense)                     (None, 10)                      110         \n",
      "________________________________________________________________________________\n",
      "dense_output (Dense)                (None, 1)                       11          \n",
      "================================================================================\n",
      "Total params: 18,681\n",
      "Trainable params: 18,681\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "set.seed(1)\n",
    "nn2<-keras_model_sequential()\n",
    "nn2 %>%\n",
    "    layer_dense(units=10, activation='relu', input_shape = c(1855), name = 'dense_input') %>%\n",
    "    layer_dense(units=10, activation='relu', name = 'dense_2') %>%\n",
    "    #layer_dense(units=10, activation='relu', name = 'dense_3') %>%\n",
    "    #layer_dense(units=10, activation='relu', name = 'dense_4') %>%\n",
    "    #layer_dense(units=200, activation='relu', kernel_regularizer =regularizer_l2(l=0.1), name = 'dense_5') %>%\n",
    "    #layer_dense(units=200, activation='relu', kernel_regularizer =regularizer_l2(l=0.1), name = 'dense_6') %>%\n",
    "    #layer_dense(units=200, activation='relu', kernel_regularizer =regularizer_l2(l=0.1), name = 'dense_7') %>%\n",
    "    #layer_dense(units=200, activation='relu', kernel_regularizer =regularizer_l2(l=0.1), name = 'dense_8') %>%\n",
    "    #layer_dropout(rate = .0) %>%\n",
    "    layer_dense(units=1, activation='linear', name = 'dense_output')\n",
    "summary(nn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "NaN"
      ],
      "text/latex": [
       "NaN"
      ],
      "text/markdown": [
       "NaN"
      ],
      "text/plain": [
       "[1] NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get.scale <- function(scaled) {\n",
    "    if (\"scaled:center\" %in% names(attributes(scaled))) {\n",
    "        center <- attr(scaled, \"scaled:center\")\n",
    "    } else {\n",
    "        center <- rep(0, ncol(scaled))\n",
    "    }\n",
    "    if (\"scaled:scale\" %in% names(attributes(scaled))) {\n",
    "        list(center, attr(scaled, \"scaled:scale\"))\n",
    "    } else {\n",
    "        list(center, rep(1., length(center)))\n",
    "    }\n",
    "}\n",
    "data.x.scale <- function(x, scaled) {\n",
    "    s <- get.scale(scaled)\n",
    "    centered <- sweep(x, 2, s[[1]])\n",
    "    sweep(centered, 2, s[[2]], FUN = \"/\")\n",
    "}\n",
    "data.y.scale <- function(y, scaled) {\n",
    "    s <- get.scale(scaled)\n",
    "    (y - s[[1]])/s[[2]]\n",
    "}\n",
    "data.y.unscale <- function(y, scaled) {\n",
    "    s <- get.scale(scaled)\n",
    "    y * s[[2]] + s[[1]]\n",
    "}\n",
    "keras.func <- function (seed = 1,nn) {\n",
    "        tensorflow::tf$random$set_seed(seed)\n",
    "        data.train.x.prep <- as.matrix(scale(data.train.x, center = T, scale = T))\n",
    "        data.train.y.prep <- scale(data.train.y, center = T, scale = T)\n",
    "        nn %>% compile(optimizer = \"adam\", loss = \"mean_squared_error\")\n",
    "        history <- nn %>% fit(data.train.x.prep,\n",
    "                             data.train.y.prep,\n",
    "                             verbose = 0,\n",
    "                             batch_size = length(data.train.y.prep),\n",
    "                             validation_split = 0.1,\n",
    "                            epochs = 500)\n",
    "        nn.pred <- predict(nn, as.matrix(data.x.scale(data.test.x, data.train.x.prep)))\n",
    "        mean((data.y.unscale(nn.pred, data.train.y.prep) - data.test.y)^2)\n",
    "    \n",
    "}\n",
    "keras.func(2,nn2)\n",
    "#keras.res <- sapply(1:2, keras.func,nn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`geom_smooth()` using formula 'y ~ x'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>loss:</strong> 0.276414573192596"
      ],
      "text/latex": [
       "\\textbf{loss:} 0.276414573192596"
      ],
      "text/markdown": [
       "**loss:** 0.276414573192596"
      ],
      "text/plain": [
       "     loss \n",
       "0.2764146 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAPACAMAAADNCOCpAAAAP1BMVEUAAAAAv8QzMzNNTU1o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\nXOEZsHOFZ8DOFZ4BO1d4/w8bUOTNZdkdLQAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 480,
       "width": 480
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorflow::tf$random$set_seed(4)\n",
    "history2<-compile_and_fit(nn2,\n",
    "                          data.y=data.train.y.scaled,valid.split=0.1)\n",
    "plot(history2)\n",
    "evaluate(nn2,as.matrix(data.test.x),data.test.y.scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow::tf$random$set_seed(2)\n",
    "nn2 %>% compile(loss='MSE',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifH<-nn2 %>% fit(as.matrix(data[,-1]),\n",
    "                    data[,1],\n",
    "                    epochs=100,\n",
    "                    callbacks=callback_early_stopping(monitor='val_loss',patience = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred<-predict(nn2,as.matrix(data.final.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.sub<-cbind(which(pred==pred),pred)\n",
    "colnames(pred.sub)<-c(\"id\",\"VALENCE.PLEASANTNESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 20 × 2 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>id</th><th scope=col>VALENCE.PLEASANTNESS</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>42.70423</td></tr>\n",
       "\t<tr><td> 2</td><td>60.12391</td></tr>\n",
       "\t<tr><td> 3</td><td>47.28643</td></tr>\n",
       "\t<tr><td> 4</td><td>52.46857</td></tr>\n",
       "\t<tr><td> 5</td><td>27.02774</td></tr>\n",
       "\t<tr><td> 6</td><td>60.73274</td></tr>\n",
       "\t<tr><td> 7</td><td>37.09969</td></tr>\n",
       "\t<tr><td> 8</td><td>52.58574</td></tr>\n",
       "\t<tr><td> 9</td><td>58.57777</td></tr>\n",
       "\t<tr><td>10</td><td>50.08640</td></tr>\n",
       "\t<tr><td>11</td><td>24.89151</td></tr>\n",
       "\t<tr><td>12</td><td>45.57832</td></tr>\n",
       "\t<tr><td>13</td><td>25.74657</td></tr>\n",
       "\t<tr><td>14</td><td>44.30614</td></tr>\n",
       "\t<tr><td>15</td><td>49.37616</td></tr>\n",
       "\t<tr><td>16</td><td>51.10914</td></tr>\n",
       "\t<tr><td>17</td><td>32.54017</td></tr>\n",
       "\t<tr><td>18</td><td>39.27640</td></tr>\n",
       "\t<tr><td>19</td><td>33.72723</td></tr>\n",
       "\t<tr><td>20</td><td>58.85876</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 20 × 2 of type dbl\n",
       "\\begin{tabular}{ll}\n",
       " id & VALENCE.PLEASANTNESS\\\\\n",
       "\\hline\n",
       "\t  1 & 42.70423\\\\\n",
       "\t  2 & 60.12391\\\\\n",
       "\t  3 & 47.28643\\\\\n",
       "\t  4 & 52.46857\\\\\n",
       "\t  5 & 27.02774\\\\\n",
       "\t  6 & 60.73274\\\\\n",
       "\t  7 & 37.09969\\\\\n",
       "\t  8 & 52.58574\\\\\n",
       "\t  9 & 58.57777\\\\\n",
       "\t 10 & 50.08640\\\\\n",
       "\t 11 & 24.89151\\\\\n",
       "\t 12 & 45.57832\\\\\n",
       "\t 13 & 25.74657\\\\\n",
       "\t 14 & 44.30614\\\\\n",
       "\t 15 & 49.37616\\\\\n",
       "\t 16 & 51.10914\\\\\n",
       "\t 17 & 32.54017\\\\\n",
       "\t 18 & 39.27640\\\\\n",
       "\t 19 & 33.72723\\\\\n",
       "\t 20 & 58.85876\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 20 × 2 of type dbl\n",
       "\n",
       "| id | VALENCE.PLEASANTNESS |\n",
       "|---|---|\n",
       "|  1 | 42.70423 |\n",
       "|  2 | 60.12391 |\n",
       "|  3 | 47.28643 |\n",
       "|  4 | 52.46857 |\n",
       "|  5 | 27.02774 |\n",
       "|  6 | 60.73274 |\n",
       "|  7 | 37.09969 |\n",
       "|  8 | 52.58574 |\n",
       "|  9 | 58.57777 |\n",
       "| 10 | 50.08640 |\n",
       "| 11 | 24.89151 |\n",
       "| 12 | 45.57832 |\n",
       "| 13 | 25.74657 |\n",
       "| 14 | 44.30614 |\n",
       "| 15 | 49.37616 |\n",
       "| 16 | 51.10914 |\n",
       "| 17 | 32.54017 |\n",
       "| 18 | 39.27640 |\n",
       "| 19 | 33.72723 |\n",
       "| 20 | 58.85876 |\n",
       "\n"
      ],
      "text/plain": [
       "      id VALENCE.PLEASANTNESS\n",
       " [1,]  1 42.70423            \n",
       " [2,]  2 60.12391            \n",
       " [3,]  3 47.28643            \n",
       " [4,]  4 52.46857            \n",
       " [5,]  5 27.02774            \n",
       " [6,]  6 60.73274            \n",
       " [7,]  7 37.09969            \n",
       " [8,]  8 52.58574            \n",
       " [9,]  9 58.57777            \n",
       "[10,] 10 50.08640            \n",
       "[11,] 11 24.89151            \n",
       "[12,] 12 45.57832            \n",
       "[13,] 13 25.74657            \n",
       "[14,] 14 44.30614            \n",
       "[15,] 15 49.37616            \n",
       "[16,] 16 51.10914            \n",
       "[17,] 17 32.54017            \n",
       "[18,] 18 39.27640            \n",
       "[19,] 19 33.72723            \n",
       "[20,] 20 58.85876            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(pred.sub,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(pred.sub,\"submisson_nn_30_20_d01_20_10_1.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.170437601296596"
      ],
      "text/latex": [
       "0.170437601296596"
      ],
      "text/markdown": [
       "0.170437601296596"
      ],
      "text/plain": [
       "[1] 0.1704376"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first build a very network simple, without any regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "dense_input (Dense)                 (None, 10)                      18560       \n",
      "________________________________________________________________________________\n",
      "dense_2 (Dense)                     (None, 10)                      110         \n",
      "________________________________________________________________________________\n",
      "dense_output (Dense)                (None, 1)                       11          \n",
      "================================================================================\n",
      "Total params: 18,681\n",
      "Trainable params: 18,681\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn1<-keras_model_sequential()\n",
    "nn1 %>%\n",
    "    layer_dense(units=10, activation='relu', input_shape = c(1855), name = 'dense_input') %>%\n",
    "    layer_dense(units=10, activation='relu',name = 'dense_2') %>%\n",
    "    layer_dense(units=1, activation='linear', name = 'dense_output')\n",
    "summary(nn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a function for compiling and fitting a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "dense_input (Dense)                 (None, 10)                      18560       \n",
      "________________________________________________________________________________\n",
      "dense_2 (Dense)                     (None, 20)                      220         \n",
      "________________________________________________________________________________\n",
      "dense_output (Dense)                (None, 1)                       21          \n",
      "================================================================================\n",
      "Total params: 18,801\n",
      "Trainable params: 18,801\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn1<-keras_model_sequential()\n",
    "nn1 %>%\n",
    "    layer_dense(units=10, activation='relu', input_shape = c(1855), name = 'dense_input') %>%\n",
    "    layer_dense(units=20, activation='relu',name = 'dense_2') %>%\n",
    "    layer_dense(units=1, activation='linear', name = 'dense_output')\n",
    "summary(nn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`geom_smooth()` using formula 'y ~ x'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>loss:</strong> 465.625915527344"
      ],
      "text/latex": [
       "\\textbf{loss:} 465.625915527344"
      ],
      "text/markdown": [
       "**loss:** 465.625915527344"
      ],
      "text/plain": [
       "    loss \n",
       "465.6259 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAPACAMAAADNCOCpAAAAP1BMVEUAAAAAv8QzMzNNTU1o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\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 480,
       "width": 480
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorflow::tf$random$set_seed(1)\n",
    "history.stop<-compile_and_fit(nn,valid.split=0.1,\n",
    "                               callbacks=callback_early_stopping(monitor='val_loss',patience = 20))\n",
    "history.stop$params$epochs<-length(history2.stop$metrics$loss)\n",
    "plot(history.stop)\n",
    "evaluate(nn,as.matrix(data.test.x),data.test.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn1<-keras_model_sequential()\n",
    "    nn1 %>%\n",
    "#        layer_dense(units=50, activation='relu', input_shape = c(1855), name = 'dense_input') %>%\n",
    " #       layer_dense(units=20, activation='relu', name = 'dense_1') %>%\n",
    "  #      layer_dense(units=10, activation='relu', name = 'dense_2') %>%\n",
    "   #     layer_dense(units=10, activation='relu', name = 'dense_3') %>%\n",
    "        layer_dense(units=40, activation='relu', input_shape = c(1855), name = 'dense_input') %>%\n",
    "        layer_dense(units=20, activation='relu', name = 'dense_2') %>%\n",
    "        layer_dropout(rate=.1)%>%\n",
    "        layer_dense(units=20, activation='relu', name = 'dense_3') %>%\n",
    "        layer_dense(units=10, activation='relu', name = 'dense_4') %>%\n",
    "        layer_dense(units=10, activation='relu', name = 'dense_5') %>%\n",
    "        layer_dense(units=10, activation='relu', name = 'dense_6') %>%\n",
    "        layer_dense(units=1, activation='linear', name = 'dense_output')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.nn.scale<-function(seed,valid.data=NULL,callbacks=NULL){\n",
    "    tensorflow::tf$random$set_seed(seed)\n",
    "    data.train.x.nozerovar<-as.matrix(data.train.x[,!sapply(data.train.x,function(x) var(x)==0)])\n",
    "    print(dim(data.train.x.nozerovar))\n",
    "    data.train.x.scaled<-scale(data.train.x.nozerovar)\n",
    "    print(dim(data.train.x.scaled))\n",
    "    data.train.y.scaled<-scale(data.train.y, center=T,scale=T)\n",
    "    nn<-keras_model_sequential()\n",
    "    nn %>%\n",
    "        layer_dense(units=60, activation='relu', input_shape = c(1850), name = 'dense_input') %>%\n",
    "        layer_dense(units=80, activation='relu', name = 'dense_2') %>%\n",
    "        layer_dropout(rate=.1)%>%\n",
    "        layer_dense(units=50, activation='relu', name = 'dense_3') %>%\n",
    "        layer_dropout(rate=.1)%>%\n",
    "        layer_dense(units=20, activation='relu', name = 'dense_4') %>%\n",
    "        layer_dense(units=10, activation='relu', name = 'dense_5') %>%\n",
    "        layer_dense(units=10, activation='relu', name = 'dense_6') %>%\n",
    "        layer_dense(units=1, activation='linear', name = 'dense_output')\n",
    "    hist<-compile_and_fit(nn,\n",
    "                        data.x=data.train.x.scaled,\n",
    "                        data.y=data.train.y.scaled,\n",
    "                        valid.split=0.1,\n",
    "                        #valid.data=list(data.x.scale(as.matrix(data.test.x),data.train.x.scaled),\n",
    "                             #data.y.scale(data.test.y,data.train.y.scaled)),\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "    ifelse(callbacks == NULL,,hist$params$epochs<-length(hist$metrics$loss))\n",
    "    if(seed==2)print(plot(hist))\n",
    "    nn.pred<-predict(nn,as.matrix(data.test.x))\n",
    "    print(head(nn.pred))\n",
    "    mean((data.y.unscale(nn.pred,data.train.y.scaled) - data.test.y)^2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  472 1850\n",
      "[1]  472 1850\n",
      "[1]  472 1850\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in py_call_impl(callable, dots$args, dots$keywords): ValueError: in user code:\n\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_71 is incompatible with the layer: expected axis -1 of input shape to have value 1850 but received input with shape [None, 1855]\n\n\nDetailed traceback: \n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 130, in _method_wrapper\n    return method(self, *args, **kwargs)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1599, in predict\n    tmp_batch_outputs = predict_function(iterator)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 780, in __call__\n    result = self._call(*args, **kwds)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 823, in _call\n    self._initialize(args, kwds, add_initializers_to=initializers)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 696, in _initialize\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3213, in _maybe_define_function\n    graph_function = self._create_graph_function(args, kwargs)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3065, in _create_graph_function\n    func_graph_module.func_graph_from_py_func(\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 986, in func_graph_from_py_func\n    func_outputs = python_func(*func_args, **func_kwargs)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 600, in wrapped_fn\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 973, in wrapper\n    raise e.ag_error_metadata.to_exception(e)\n\n",
     "output_type": "error",
     "traceback": [
      "Error in py_call_impl(callable, dots$args, dots$keywords): ValueError: in user code:\n\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_71 is incompatible with the layer: expected axis -1 of input shape to have value 1850 but received input with shape [None, 1855]\n\n\nDetailed traceback: \n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 130, in _method_wrapper\n    return method(self, *args, **kwargs)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1599, in predict\n    tmp_batch_outputs = predict_function(iterator)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 780, in __call__\n    result = self._call(*args, **kwds)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 823, in _call\n    self._initialize(args, kwds, add_initializers_to=initializers)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 696, in _initialize\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3213, in _maybe_define_function\n    graph_function = self._create_graph_function(args, kwargs)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3065, in _create_graph_function\n    func_graph_module.func_graph_from_py_func(\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 986, in func_graph_from_py_func\n    func_outputs = python_func(*func_args, **func_kwargs)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 600, in wrapped_fn\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n  File \"C:\\Users\\totol\\ANACON~1\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 973, in wrapper\n    raise e.ag_error_metadata.to_exception(e)\n\nTraceback:\n",
      "1. keras.nn.scale(90)",
      "2. predict(nn, as.matrix(data.test.x))   # at line 29 of file <text>",
      "3. predict.keras.engine.training.Model(nn, as.matrix(data.test.x))",
      "4. do.call(object$predict, args)",
      "5. (structure(function (...) \n . {\n .     dots <- py_resolve_dots(list(...))\n .     result <- py_call_impl(callable, dots$args, dots$keywords)\n .     if (convert) \n .         result <- py_to_r(result)\n .     if (is.null(result)) \n .         invisible(result)\n .     else result\n . }, class = c(\"python.builtin.method\", \"python.builtin.object\"\n . ), py_object = <environment>))(batch_size = 32L, verbose = 0L, \n .     callbacks = list(), x = <environment>)",
      "6. py_call_impl(callable, dots$args, dots$keywords)"
     ]
    }
   ],
   "source": [
    "keras.res.scale<-keras.nn.scale(90)\n",
    "cat(' RMSE mean on the test set over ',d,' different seeds, using scaled data : ',sqrt(mean(keras.res.scale)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "get.scale <- function(scaled) {\n",
    "    if (\"scaled:center\" %in% names(attributes(scaled))) {\n",
    "        center <- attr(scaled, \"scaled:center\")\n",
    "    } else {\n",
    "        center <- rep(0, ncol(scaled))\n",
    "    }\n",
    "    if (\"scaled:scale\" %in% names(attributes(scaled))) {\n",
    "        list(center, attr(scaled, \"scaled:scale\"))\n",
    "    } else {\n",
    "        list(center, rep(1., length(center)))\n",
    "    }\n",
    "}\n",
    "data.x.scale <- function(x, scaled) {\n",
    "    s <- get.scale(scaled)\n",
    "    centered <- sweep(x, 2, s[[1]])\n",
    "    sweep(centered, 2, s[[2]], FUN = \"/\")\n",
    "}\n",
    "data.y.scale <- function(y, scaled) {\n",
    "    s <- get.scale(scaled)\n",
    "    (y - s[[1]])/s[[2]]\n",
    "}\n",
    "data.y.unscale <- function(y, scaled) {\n",
    "    s <- get.scale(scaled)\n",
    "    y * s[[2]] + s[[1]]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
