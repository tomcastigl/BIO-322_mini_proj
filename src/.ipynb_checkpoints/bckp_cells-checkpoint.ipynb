{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data we are interested in is VALENCE.PLEASANTNESS, wich take values between 0 and 100. The objective is to create a model estimating the VALENCE.PLEASANTNESS given the inputs \"Intensity, \"SWEETORSOUR\"(sure?), and V2 to V11787, which represent the presence or not of a corresponding physiochemical feature in the smelled molecule. At first sight of the data plotted above, we can see that the SWEETORSOUR variable seems have a relatively big impact on VALENCE.PLEASANTNESS (actually it does not proves anything, it is just an early observation). Now we look at some randomly chosen physiochemical features comparing the means of VALENCE.PLEASANTNESS when they are present or not.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the means with or without some randomly chosen physiochemical features\n",
    "for(col in sample(2:nrow(data),7)){\n",
    "    idx.presence<-c()\n",
    "    idx.nonpresence<-c()\n",
    "    for(i in 1:nrow(data)){\n",
    "        if(data[col,i]==1){\n",
    "            idx.presence<-append(idx.presence,i)\n",
    "        }else{\n",
    "            idx.nonpresence<-append(idx.nonpresence,i)\n",
    "        }\n",
    "    }\n",
    "    #message(\"presence mean of \", colnames(data)[col],\" \",mean(data$VALENCE.PLEASANTNESS[idx.presence]))\n",
    "    #message(\"nonpresence mean \",colnames(data)[col],\" \",mean(data$VALENCE.PLEASANTNESS[idx.nonpresence]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data$Intensity<-as.integer(as.factor(data$Intensity)) #\"high\"->1, \"low\"->2\n",
    "data$SWEETORSOUR <-as.integer(data$SWEETORSOUR)   #\"FALSE\"->0, \"TRUE\"->1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Let's start to create a basic linear regression model on all the data. This model will be the base to be improved to try and get the best linear model. We separate all the data in a training set (2/3 of the whole data is taken as training set because we will separate it in a validation and actual training set later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a training (for now, it will be split later) and test set.\n",
    "idx.train<-sample(nrow(data),nrow(data)*(2/3))\n",
    "data.test<-data[-idx.train,]\n",
    "data<-data[idx.train,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next cell is really slow, because of all the predictors (11789 !!!), and since p>>n we will largely overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic.lm.fit<-lm(VALENCE.PLEASANTNESS~.,data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in predict(basic.lm.fit, data = data): objet 'basic.lm.fit' introuvable\n",
     "output_type": "error",
     "traceback": [
      "Error in predict(basic.lm.fit, data = data): objet 'basic.lm.fit' introuvable\nTraceback:\n",
      "1. predict(basic.lm.fit, data = data)"
     ]
    }
   ],
   "source": [
    "train.pred<-predict(basic.lm.fit,data=data)\n",
    "test.pred<-predict(basic.lm.fit,data=data.test)\n",
    "trainMSE<-mean((data$VALENCE.PLEASANTNESS-train.pred)^2)\n",
    "testMSE<-mean((data.test$VALENCE.PLEASANTNESS-test.pred)^2)\n",
    "cat(\"train MSE: \",trainMSE, \"\\n\")\n",
    "cat(\"test MSE: \",testMSE)\n",
    "\n",
    "#summary(basic.lm.fit)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, as predicted, we largely overfit the data when using all predictors for linear regression. Also, consequently to p>>n, a large part of the predictors parameters are NAs. We will use cross validation to try and get the number of predictors that gives the lowest validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidymodels)\n",
    "library(leaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"11487  linear dependencies found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], : NA/NaN/Inf dans un appel à une fonction externe (argument 4)\n",
     "output_type": "error",
     "traceback": [
      "Error in leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], : NA/NaN/Inf dans un appel à une fonction externe (argument 4)\nTraceback:\n",
      "1. regsubsets(VALENCE.PLEASANTNESS ~ ., data, method = \"forward\", \n .     nvmax = 20)",
      "2. regsubsets.formula(VALENCE.PLEASANTNESS ~ ., data, method = \"forward\", \n .     nvmax = 20)",
      "3. leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, \n .     force.out = force.out, intercept = intercept)",
      "4. leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], \n .     force.out[reorder], intercept, nvmax, nbest, warn.dep = FALSE)"
     ]
    }
   ],
   "source": [
    "#testing cell\n",
    "validation.data<-vfold_cv(data, v=5)\n",
    "fit<-regsubsets(VALENCE.PLEASANTNESS~.,data, method=\"forward\", nvmax=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"11519  linear dependencies found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], : NA/NaN/Inf dans un appel à une fonction externe (argument 4)\n",
     "output_type": "error",
     "traceback": [
      "Error in leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], : NA/NaN/Inf dans un appel à une fonction externe (argument 4)\nTraceback:\n",
      "1. sapply(validation.data$splits, cv_fit_and_eval)",
      "2. lapply(X = X, FUN = FUN, ...)",
      "3. FUN(X[[i]], ...)",
      "4. regsubsets(formula, analysis(fold), method = \"forward\", nvmax = 30)   # at line 4 of file <text>",
      "5. regsubsets.formula(formula, analysis(fold), method = \"forward\", \n .     nvmax = 30)",
      "6. leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, \n .     force.out = force.out, intercept = intercept)",
      "7. leaps.setup(x[, ii[reorder], drop = FALSE], y, wt, force.in[reorder], \n .     force.out[reorder], intercept, nvmax, nbest, warn.dep = FALSE)"
     ]
    }
   ],
   "source": [
    "validation.data<-vfold_cv(data, v=5)\n",
    "\n",
    "cv_fit_and_eval <- function(fold, formula=VALENCE.PLEASANTNESS ~ .) {\n",
    "    fit<-regsubsets(formula, analysis(fold), method=\"forward\", nvmax=30)\n",
    "    validation.set<-assessment(fold)\n",
    "    sapply(seq(1,fit$nvmax-1),\n",
    "           function(idx) fitmean(validation.set$VALENCE.PLEASANTNESS-predict(fit,validation.set,idx,formula)^2))\n",
    "    str(fit)\n",
    "}\n",
    "cv.errors<-sapply(validation.data$splits,cv_fit_and_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
